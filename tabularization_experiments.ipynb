{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda802f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tabularization Refactoring Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8b201c-108b-45eb-ac6f-c966c18a343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from darts.utils.data.tabularization import (\n",
    "    _create_lagged_data,\n",
    "    create_lagged_training_data,\n",
    "    create_lagged_prediction_data,\n",
    ")\n",
    "from darts.utils.timeseries_generation import linear_timeseries\n",
    "from tab_experiment_utils import perform_benchmarks, perform_profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6fc0b2-7ae3-4ff6-8094-72a7e90414de",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bugs in Current Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01368b2d-c636-44c2-a28c-4ae619740daa",
   "metadata": {},
   "source": [
    "The currently implemented `_create_lagged_data` does not correctly handle cases where training/prediction observations can be created for times that are *not* included in all of the provided time series. The easiest way to illustrate what I mean by this is through an example; suppose we wanted to create training/prediction data using the following three time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33908801-c026-49c0-8f54-a2fd497afb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries to create data from:\n",
    "target_series = linear_timeseries(start=0, length=6, freq=1)\n",
    "past_covariates = linear_timeseries(start=0, length=4, freq=1)\n",
    "future_covariates = linear_timeseries(start=0, length=4, freq=1)\n",
    "# Lags to use for each timeseries:\n",
    "lags = [-1]\n",
    "lags_past_covariates = [-3]\n",
    "lags_future_covariates = [-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1804eb-f1ad-442f-85d8-08dce7cd16e0",
   "metadata": {},
   "source": [
    "For the sake of clarity, let's 'visualise' what each of these timeseries look like - the values are shown in the top row, and the time index is shown in the bottom row of each array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d5056f-ca06-4ed7-8134-982fd67b1fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.2 0.4 0.6 0.8 1. ]\n",
      " [0.  1.  2.  3.  4.  5. ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.stack([target_series.all_values().squeeze(), target_series.time_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b62c87-0d0d-4c2e-ae3a-3c3df8e528b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.33333333 0.66666667 1.        ]\n",
      " [0.         1.         2.         3.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.stack([past_covariates.all_values().squeeze(), past_covariates.time_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15d7447d-61f0-4295-81dd-44e0605da673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.33333333 0.66666667 1.        ]\n",
      " [0.         1.         2.         3.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.stack([future_covariates.all_values().squeeze(), future_covariates.time_index])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b0bc6c-8dae-4bc2-9bfb-b88dab5003ac",
   "metadata": {},
   "source": [
    "In this scenario, we're actually *able* create create training data for the time point `5`, even though the `past_covariates` and `future_covariates` timeseries only go up to the `3` time point. This is because constructing the feature vector for time `5` only requires us to know the values of `past_covariates` and `future_covariates` `[-3]` lags away from time `5` (i.e. their values at time `2`). Indeed, `create_lagged_training_data` (i.e. one of the newly implemented functions) returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c215f304-df61-4cde-9347-a82b67794dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[0.8        0.66666667 0.66666667]]\n",
      "y = [[1.]]\n",
      "times = [5]\n"
     ]
    }
   ],
   "source": [
    "X, y, times = create_lagged_training_data(\n",
    "    target_series=target_series,\n",
    "    output_chunk_length=1,\n",
    "    past_covariates=past_covariates,\n",
    "    future_covariates=future_covariates,\n",
    "    lags=lags,\n",
    "    lags_past_covariates=lags_past_covariates,\n",
    "    lags_future_covariates=lags_future_covariates,\n",
    "    max_samples_per_ts=1,\n",
    ")\n",
    "print(f\"X = {X[:,:,0]}\")\n",
    "print(f\"y = {y[:,:,0]}\")\n",
    "print(f\"times = {list(times)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9099e8fb-fb7f-4fad-930b-e8fdf19e4711",
   "metadata": {},
   "source": [
    "i.e. the time `5` value of `target_series` is used as the `y` label for the 'latest' possible sample. If we use these inputs with the current implementation, however:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21662e42-f992-4cea-b295-c1c4011046cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[0.4 0.  0. ]]\n",
      "y = [[0.6]]\n",
      "times = [3]\n"
     ]
    }
   ],
   "source": [
    "X, y, times = _create_lagged_data(\n",
    "    target_series=target_series,\n",
    "    output_chunk_length=1,\n",
    "    past_covariates=past_covariates,\n",
    "    future_covariates=future_covariates,\n",
    "    lags=lags,\n",
    "    lags_past_covariates=lags_past_covariates,\n",
    "    lags_future_covariates=lags_future_covariates,\n",
    "    max_samples_per_ts=1,\n",
    "    is_training=True,\n",
    ")\n",
    "print(f\"X = {X[:,:]}\")\n",
    "print(f\"y = {y[:,:]}\")\n",
    "print(f\"times = {list(times[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e1da7-e88a-4b6d-ad89-9073b71d1ff7",
   "metadata": {},
   "source": [
    "i.e. the 'lastest' observation produced is for time `3`, which is the latest times present in `past_covariates` and `future_covariates`. This illustrates that the currently implemented `_create_lagged_data` is does not return all of the training samples it *could* possible construct.\n",
    "\n",
    "In the case of constructing prediction features, we don't need to concern ourselves with creating a label for each generated feature, which means that we're able to create prediction features for times that extend even beyond the times contained in `target_series`. In the current example, we're actually able to construct features to predict the series at time `6`, since predicting the series at this time only requires us to know the value of `target_series` `[-1]` lags away (i.e. at time `5`), and the values of `past_covariates` and `future_covariates` `[-3]` lags away (i.e. at time `3`). Let's see this by calling `create_lagged_prediction_data` (i.e. another newly implemented function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de3a84ed-6a53-4093-9f21-21af95c5dc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[1. 1. 1.]]\n",
      "times = [6]\n"
     ]
    }
   ],
   "source": [
    "X, times = create_lagged_prediction_data(\n",
    "    target_series=target_series,\n",
    "    past_covariates=past_covariates,\n",
    "    future_covariates=future_covariates,\n",
    "    lags=lags,\n",
    "    lags_past_covariates=lags_past_covariates,\n",
    "    lags_future_covariates=lags_future_covariates,\n",
    "    max_samples_per_ts=1,\n",
    ")\n",
    "print(f\"X = {X[:,:,0]}\")\n",
    "print(f\"times = {list(times)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebab518-feed-46fb-92ee-afc362964654",
   "metadata": {},
   "source": [
    "Here we see that the last values of `target_series`, `past_covariates`, and `future_covariates` can be used to construct an `X` array that can predict the series values at time `6`, as we expected. When calling the currently implemented `_create_lagged_data`, one finds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65270f42-43ba-488c-8491-f60a60eeccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[0.8        0.66666667 0.66666667]]\n",
      "times = [5]\n"
     ]
    }
   ],
   "source": [
    "X, _, times = _create_lagged_data(\n",
    "    target_series=target_series,\n",
    "    output_chunk_length=1,\n",
    "    past_covariates=past_covariates,\n",
    "    future_covariates=future_covariates,\n",
    "    lags=lags,\n",
    "    lags_past_covariates=lags_past_covariates,\n",
    "    lags_future_covariates=lags_future_covariates,\n",
    "    max_samples_per_ts=1,\n",
    "    is_training=False,\n",
    ")\n",
    "print(f\"X = {X[:,:]}\")\n",
    "print(f\"times = {list(times[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea577270-0300-4fbf-90ef-fd58ca8988f4",
   "metadata": {},
   "source": [
    "i.e. `_create_lagged_data` is unable to create the prediction data point for time `6`; instead, it only returns the prediction data point for time `5`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38899c53-9ab3-4ad1-b6bc-8b7714c581b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Speed Benchmarks\n",
    "\n",
    "In this section, a few different benchmarks of `_create_lagged_data` vs `create_lagged_training_data` are performed. It should be noted that these benchmarks are slightly biased *against* the current implementations for benchmarks where `max_samples_per_ts` is set to `None`, since the newly implemented functions are constructing more training observations than the current implementation (see the previous section to understand why). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9db14-2c2e-4585-86e4-47db1d0302f9",
   "metadata": {},
   "source": [
    "### Small Number of Lags, No `max_samples_per_ts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "312fc493-abac-41b5-8578-75accfd784a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Unequal Frequency Timeseries:\n",
      "Current implementation: 19.23994779586792 secs for 1000 repetitions\n",
      "New implementation: 1.354933500289917 secs for 1000 repetitions\n",
      "Speed up = 14.199920359007377 fold\n",
      "\n",
      "With Equal Frequency Timeseries, Using Moving Windows:\n",
      "Current implementation: 10.251362085342407 secs for 1000 repetitions\n",
      "New implementation: 1.0340075492858887 secs for 1000 repetitions\n",
      "Speed up = 9.914204294177788 fold\n",
      "\n",
      "With Equal Frequency Timeseries, Using Time Intersections:\n",
      "Current implementation: 10.053273677825928 secs for 1000 repetitions\n",
      "New implementation: 3.6990296840667725 secs for 1000 repetitions\n",
      "Speed up = 2.717813733998803 fold\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perform_benchmarks(\n",
    "    num_repeats=1000,\n",
    "    use_range_idx=False,\n",
    "    multi_models=True,\n",
    "    lags=[-1],\n",
    "    lags_past_covariates=[-2],\n",
    "    lags_future_covariates=[-3],\n",
    "    output_chunk_length=10,\n",
    "    max_samples_per_ts=None,\n",
    "    check_inputs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d587da-d221-489b-8ddf-0acee5f037bb",
   "metadata": {},
   "source": [
    "### Small Number of Lags, `max_samples_per_ts` = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6f50ab1-bc1b-4a55-b298-7a0129d8a547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Unequal Frequency Timeseries:\n",
      "Current implementation: 20.565967321395874 secs for 1000 repetitions\n",
      "New implementation: 0.9422202110290527 secs for 1000 repetitions\n",
      "Speed up = 21.82713454950685 fold\n",
      "\n",
      "With Equal Frequency Timeseries, Using Moving Windows:\n",
      "Current implementation: 10.45595407485962 secs for 1000 repetitions\n",
      "New implementation: 0.7731902599334717 secs for 1000 repetitions\n",
      "Speed up = 13.523132166407903 fold\n",
      "\n",
      "With Equal Frequency Timeseries, Using Time Intersections:\n",
      "Current implementation: 10.36695122718811 secs for 1000 repetitions\n",
      "New implementation: 1.0335073471069336 secs for 1000 repetitions\n",
      "Speed up = 10.030844247220893 fold\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perform_benchmarks(\n",
    "    num_repeats=1000,\n",
    "    use_range_idx=False,\n",
    "    multi_models=True,\n",
    "    lags=[-1],\n",
    "    lags_past_covariates=[-2],\n",
    "    lags_future_covariates=[-3],\n",
    "    output_chunk_length=10,\n",
    "    max_samples_per_ts=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa483dd-5b5d-4f9f-8c68-6e35341e2259",
   "metadata": {},
   "source": [
    "### Large Number of Lags, No `max_samples_per_ts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8a7f775-de0b-4d90-aa4b-09175b8ad8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Unequal Frequency Timeseries:\n",
      "Current implementation: 29.16094398498535 secs for 100 repetitions\n",
      "New implementation: 0.6532535552978516 secs for 100 repetitions\n",
      "Speed up = 44.63954883749449 fold\n",
      "\n",
      "With Equal Frequency Timeseries, Using Moving Windows:\n",
      "Current implementation: 10.20738697052002 secs for 100 repetitions\n",
      "New implementation: 2.484281539916992 secs for 100 repetitions\n",
      "Speed up = 4.108788318276149 fold\n",
      "\n",
      "With Equal Frequency Timeseries, Using Time Intersections:\n",
      "Current implementation: 9.86971116065979 secs for 100 repetitions\n",
      "New implementation: 2.7644736766815186 secs for 100 repetitions\n",
      "Speed up = 3.570195384355194 fold\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use fewer repeats here for sake of brevity (these benchmarks take longer):\n",
    "perform_benchmarks(\n",
    "    num_repeats=100,\n",
    "    use_range_idx=False,\n",
    "    multi_models=True,\n",
    "    lags=range(-30, 0, 1),\n",
    "    lags_past_covariates=range(-62, 0, 2),\n",
    "    lags_future_covariates=range(-100, 0, 3),\n",
    "    output_chunk_length=10,\n",
    "    max_samples_per_ts=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c1bba6-8718-4002-b7fc-909a5203b2d0",
   "metadata": {},
   "source": [
    "### Large Number of Lags, `max_samples_per_ts` = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddae8be7-3e26-4990-8693-29206703af17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Unequal Frequency Timeseries:\n",
      "Current implementation: 28.617480516433716 secs for 100 repetitions\n",
      "New implementation: 0.11005711555480957 secs for 100 repetitions\n",
      "Speed up = 260.02390097332614 fold\n",
      "\n",
      "With Equal Frequency Timeseries, Using Moving Windows:\n",
      "Current implementation: 9.818582773208618 secs for 100 repetitions\n",
      "New implementation: 0.07866573333740234 secs for 100 repetitions\n",
      "Speed up = 124.81397371707057 fold\n",
      "\n",
      "With Equal Frequency Timeseries, Using Time Intersections:\n",
      "Current implementation: 9.515854835510254 secs for 100 repetitions\n",
      "New implementation: 0.10745787620544434 secs for 100 repetitions\n",
      "Speed up = 88.55427979348185 fold\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use fewer repeats here for sake of brevity (these benchmarks take longer):\n",
    "perform_benchmarks(\n",
    "    num_repeats=100,\n",
    "    use_range_idx=False,\n",
    "    multi_models=True,\n",
    "    lags=range(-30, 0, 1),\n",
    "    lags_past_covariates=range(-62, 0, 2),\n",
    "    lags_future_covariates=range(-100, 0, 3),\n",
    "    output_chunk_length=10,\n",
    "    max_samples_per_ts=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56762b5-d117-450e-ba93-10d3523357d0",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bbf00a-6bbc-407e-902d-610f4ccebca3",
   "metadata": {},
   "source": [
    "To help understand which parts of `create_lagged_training_data` contribute most to run time, we'll profile 1000 repeated calls to this function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af5b960-fa71-4073-8643-d33cab4ea782",
   "metadata": {},
   "source": [
    "### When Using 'Moving Windows' Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "798384b0-b246-482e-846a-8cb4401affb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         727002 function calls (717002 primitive calls) in 1.178 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 105 to 14 due to restriction <'tabularization.py'>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     1000    0.006    0.000    1.178    0.001 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:231(create_lagged_data)\n",
      "     1000    0.062    0.000    1.166    0.001 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:455(_create_lagged_data_by_moving_window)\n",
      "     3000    0.099    0.000    0.317    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:579(_extract_lagged_vals_from_windows)\n",
      "     1000    0.019    0.000    0.161    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:706(get_feature_times)\n",
      "     3000    0.007    0.000    0.053    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:1085(_extend_time_index)\n",
      "     3000    0.011    0.000    0.052    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:1002(strided_moving_window)\n",
      "     3000    0.010    0.000    0.021    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:1137(_check_series_length)\n",
      "     1000    0.009    0.000    0.020    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:926(get_shared_times_bounds)\n",
      "     1000    0.007    0.000    0.014    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:1112(_check_lags)\n",
      "     2000    0.004    0.000    0.006    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:1093(_get_freqs)\n",
      "     1000    0.002    0.000    0.005    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:1104(_all_equal_freq)\n",
      "     7000    0.002    0.000    0.003    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:1127(<genexpr>)\n",
      "     1000    0.001    0.000    0.001    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:984(<listcomp>)\n",
      "     1000    0.001    0.000    0.001    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:495(<listcomp>)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perform_profiling(\n",
    "    num_repeats=1000,\n",
    "    lags=[-1],\n",
    "    lags_past_covariates=[-1, -2],\n",
    "    lags_future_covariates=[-2],\n",
    "    output_chunk_length=1,\n",
    "    max_samples_per_ts=None,\n",
    "    multi_models=False,\n",
    "    use_moving_windows=True,\n",
    "    equal_freq=True,\n",
    "    num_timesteps=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02041631-e299-4401-93b2-477d0df2e322",
   "metadata": {},
   "source": [
    "### When Using 'Time Intersection' Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f152f40-efd1-486d-9d36-ba672807ef41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1099006 function calls (1072004 primitive calls) in 2.325 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 139 to 11 due to restriction <'tabularization.py'>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     1000    0.005    0.000    2.325    0.002 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:231(create_lagged_data)\n",
      "     1000    0.897    0.001    2.319    0.002 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:605(_create_lagged_data_by_intersecting_times)\n",
      "     1000    0.003    0.000    0.174    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:851(get_shared_times)\n",
      "     2000    0.003    0.000    0.167    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:882(intersection_func)\n",
      "     1000    0.019    0.000    0.158    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:706(get_feature_times)\n",
      "     3000    0.006    0.000    0.051    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:1085(_extend_time_index)\n",
      "     3000    0.010    0.000    0.021    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:1137(_check_series_length)\n",
      "     1000    0.008    0.000    0.015    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:1112(_check_lags)\n",
      "     7000    0.002    0.000    0.003    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:1127(<genexpr>)\n",
      "     1000    0.001    0.000    0.001    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:639(<listcomp>)\n",
      "     1000    0.001    0.000    0.001    0.000 /home/mabilton/Documents/Programming/darts/darts/utils/data/tabularization.py:895(<listcomp>)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perform_profiling(\n",
    "    num_repeats=1000,\n",
    "    lags=[-1],\n",
    "    lags_past_covariates=[-1, -2],\n",
    "    lags_future_covariates=[-2],\n",
    "    output_chunk_length=1,\n",
    "    max_samples_per_ts=None,\n",
    "    multi_models=False,\n",
    "    use_moving_windows=False,\n",
    "    equal_freq=True,\n",
    "    num_timesteps=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863f7f28-2a9b-4621-9e9a-019045603bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
