{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda802f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tabularization Refactoring Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b850f9",
   "metadata": {},
   "source": [
    "## Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8b201c-108b-45eb-ac6f-c966c18a343c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from math import inf\n",
    "from darts import TimeSeries\n",
    "from darts.utils.data.tabularization import (\n",
    "    _create_lagged_data,\n",
    "    create_lagged_features_and_labels,\n",
    "    create_lagged_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c1de7-536f-4906-b4d1-ffe25129f681",
   "metadata": {},
   "source": [
    "Utility function to create 'dummy' index time series, where $y_t = t$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8dae6ab-1256-4d96-b8a8-7c5ffe6ca011",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def create_index_series(num_timesteps, num_components, offset=0, freq=1, start=None):\n",
    "    vals = np.arange(0, num_timesteps * num_components, 1) + offset\n",
    "    vals = vals.reshape(num_timesteps, num_components, 1)\n",
    "    if not isinstance(freq, str):\n",
    "        if start is None:\n",
    "            # Default range index start:\n",
    "            start = 0\n",
    "        dates = pd.RangeIndex(start, freq * num_timesteps, freq)\n",
    "    else:\n",
    "        if start is None:\n",
    "            # Default datetime index start:\n",
    "            start = \"1/1/1900\"\n",
    "        dates = pd.date_range(start, periods=num_timesteps, freq=freq)\n",
    "    return TimeSeries.from_times_and_values(values=vals, times=dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615bcdce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6fc0b2-7ae3-4ff6-8094-72a7e90414de",
   "metadata": {},
   "source": [
    "### Correctness Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5121d7",
   "metadata": {},
   "source": [
    "Test correctness of refactored implementation vs current implementation over many different combinations of input values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877a0570-3878-4e34-ac74-dfc3b3cd0785",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed 500/10240\n",
      "Passed 1000/10240\n",
      "Passed 1500/10240\n",
      "Passed 2000/10240\n",
      "Passed 2500/10240\n",
      "Passed 3000/10240\n",
      "Passed 3500/10240\n",
      "Passed 4000/10240\n",
      "Passed 4500/10240\n",
      "Passed 5000/10240\n",
      "Passed 5500/10240\n",
      "Passed 6000/10240\n",
      "Passed 6500/10240\n",
      "Passed 7000/10240\n",
      "Passed 7500/10240\n",
      "Passed 8000/10240\n",
      "Passed 8500/10240\n",
      "Passed 9000/10240\n",
      "Passed 9500/10240\n",
      "Passed 10000/10240\n"
     ]
    }
   ],
   "source": [
    "def test_training_correctness():\n",
    "    # Timeseries with different start times, lengths, frequencies, and number of components:\n",
    "    num_timesteps = 1000\n",
    "    target_series = create_index_series(\n",
    "        num_timesteps, num_components=2, offset=10, start=\"5/1/1900\", freq=\"d\"\n",
    "    )\n",
    "    past_series = create_index_series(\n",
    "        num_timesteps - 13, num_components=3, offset=30, freq=\"2d\"\n",
    "    )\n",
    "    future_series = create_index_series(\n",
    "        num_timesteps + 5, num_components=5, offset=60, freq=\"3d\"\n",
    "    )\n",
    "\n",
    "    # With and without specifying past series:\n",
    "    past_combo = [past_series, None]\n",
    "    # With and without specifying future series:\n",
    "    future_combo = [future_series, None]\n",
    "    # Single lags, multiple lags, multiple + noncontiguous lags:\n",
    "    lag_combos = ([-1], [-2, -1], [-4, -3, -2, -1], [-6, -4, -2])\n",
    "    # Small + large horizons:\n",
    "    horizon_combos = [1, 5, 10, 20]\n",
    "    # With and without multiple model predictions:\n",
    "    multiple_output_combos = [False, True]\n",
    "    # With and without maximum number of samples:\n",
    "    max_sample_combos = [1, 5, 10, 20, None]\n",
    "    param_combos = product(\n",
    "        past_combo,\n",
    "        future_combo,\n",
    "        lag_combos,\n",
    "        lag_combos,\n",
    "        lag_combos,\n",
    "        horizon_combos,\n",
    "        multiple_output_combos,\n",
    "        max_sample_combos,\n",
    "    )\n",
    "    len_combos = (\n",
    "        len(past_combo)\n",
    "        * len(future_combo)\n",
    "        * (len(lag_combos) ** 3)\n",
    "        * len(horizon_combos)\n",
    "        * len(multiple_output_combos)\n",
    "        * len(max_sample_combos)\n",
    "    )\n",
    "    for i, (\n",
    "        past,\n",
    "        future,\n",
    "        target_lag,\n",
    "        past_lag,\n",
    "        future_lag,\n",
    "        horizon,\n",
    "        multiple_outputs,\n",
    "        max_samples,\n",
    "    ) in enumerate(param_combos):\n",
    "\n",
    "        # Current implmentation:\n",
    "        (X, y, Ts) = _create_lagged_data(\n",
    "            target_series,\n",
    "            lags=target_lag,\n",
    "            past_covariates=past_series,\n",
    "            future_covariates=future_series,\n",
    "            lags_past_covariates=past_lag,\n",
    "            lags_future_covariates=future_lag,\n",
    "            output_chunk_length=horizon,\n",
    "            multi_models=multiple_outputs,\n",
    "            is_training=True,\n",
    "            max_samples_per_ts=max_samples,\n",
    "        )\n",
    "        # Refactored implementation:\n",
    "        my_X, my_y, my_Ts = create_lagged_features_and_labels(\n",
    "            horizon=horizon,\n",
    "            target_series=target_series,\n",
    "            past_series=past_series,\n",
    "            future_series=future_series,\n",
    "            target_lags=target_lag,\n",
    "            past_lags=past_lag,\n",
    "            future_lags=future_lag,\n",
    "            max_samples=max_samples if max_samples is not None else inf,\n",
    "            multiple_outputs=multiple_outputs,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            assert np.allclose(my_X.squeeze(), X.squeeze())\n",
    "        except:\n",
    "            raise ValueError(\"X incorrect\")\n",
    "\n",
    "        try:\n",
    "            assert np.allclose(my_y.squeeze(), y.squeeze())\n",
    "        except:\n",
    "            raise ValueError(\"y incorrect\")\n",
    "\n",
    "        try:\n",
    "            assert list(my_Ts) == list(Ts[0])\n",
    "        except:\n",
    "            raise ValueError(\"Ts incorrect\")\n",
    "\n",
    "        if (i + 1) % 500 == 0:\n",
    "            print(f\"Passed {i+1}/{len_combos}\")\n",
    "\n",
    "\n",
    "test_training_correctness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38899c53-9ab3-4ad1-b6bc-8b7714c581b8",
   "metadata": {},
   "source": [
    "### Speed Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834859d7",
   "metadata": {},
   "source": [
    "Informal speed benchmarks of refactored implementation vs current implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef1d12b9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def benchmark_training_data_generation(\n",
    "    num_repeats,\n",
    "    target_lags,\n",
    "    past_lags,\n",
    "    future_lags,\n",
    "    horizon,\n",
    "    max_samples,\n",
    "    multiple_outputs,\n",
    "):\n",
    "    # Timeseries with different start times, lengths, frequencies, and number of components:\n",
    "    num_timesteps = 10000\n",
    "    target_series = create_index_series(\n",
    "        num_timesteps, num_components=2, offset=10, start=\"5/1/1900\", freq=\"d\"\n",
    "    )\n",
    "    past_series = create_index_series(\n",
    "        num_timesteps - 13, num_components=3, offset=30, freq=\"2d\"\n",
    "    )\n",
    "    future_series = create_index_series(\n",
    "        num_timesteps + 5, num_components=5, offset=60, freq=\"3d\"\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_repeats):\n",
    "        (X, y, Ts) = _create_lagged_data(\n",
    "            target_series,\n",
    "            lags=target_lags,\n",
    "            past_covariates=past_series,\n",
    "            future_covariates=future_series,\n",
    "            lags_past_covariates=past_lags,\n",
    "            lags_future_covariates=future_lags,\n",
    "            output_chunk_length=horizon,\n",
    "            multi_models=multiple_outputs,\n",
    "            is_training=True,\n",
    "            max_samples_per_ts=max_samples,\n",
    "        )\n",
    "    current_implem_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_repeats):\n",
    "        my_X, my_y, my_Ts = create_lagged_features_and_labels(\n",
    "            horizon=horizon,\n",
    "            target_series=target_series,\n",
    "            past_series=past_series,\n",
    "            future_series=future_series,\n",
    "            target_lags=target_lags,\n",
    "            past_lags=past_lags,\n",
    "            future_lags=future_lags,\n",
    "            max_samples=max_samples if max_samples is not None else inf,\n",
    "            multiple_outputs=multiple_outputs,\n",
    "        )\n",
    "    refact_implem_time = time.time() - start_time\n",
    "\n",
    "    # Ensure reimplemented function is correct:\n",
    "    assert np.allclose(my_X.squeeze(), X.squeeze())\n",
    "    assert np.allclose(my_y.squeeze(), y.squeeze())\n",
    "    assert list(my_Ts) == list(Ts[0])\n",
    "\n",
    "    return current_implem_time, refact_implem_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9db14-2c2e-4585-86e4-47db1d0302f9",
   "metadata": {},
   "source": [
    "Benchmarks with small number of lags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "312fc493-abac-41b5-8578-75accfd784a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current implementation: 26.26463222503662 secs\n",
      "New implementation: 2.086974859237671 secs\n",
      "Speed up = 12.585025693424287 fold\n"
     ]
    }
   ],
   "source": [
    "# Number of times to repeat function call for timing purposes:\n",
    "num_repeats = 1000\n",
    "multiple_outputs = True\n",
    "target_lags = [-1]\n",
    "past_lags = [-2]\n",
    "future_lags = [-3]\n",
    "horizon = 10\n",
    "max_samples = None\n",
    "old_time, new_time = benchmark_training_data_generation(\n",
    "    num_repeats,\n",
    "    target_lags,\n",
    "    past_lags,\n",
    "    future_lags,\n",
    "    horizon,\n",
    "    max_samples,\n",
    "    multiple_outputs,\n",
    ")\n",
    "print(f\"Current implementation: {old_time} secs\")\n",
    "print(f\"New implementation: {new_time} secs\")\n",
    "print(f\"Speed up = {old_time/new_time} fold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d587da-d221-489b-8ddf-0acee5f037bb",
   "metadata": {},
   "source": [
    "Benchmarks with large number of lags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90e5ba0f-8786-405a-8f20-40e138b3842d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current implementation: 49.359559774398804 secs\n",
      "New implementation: 1.2991654872894287 secs\n",
      "Speed up = 37.993281269642026 fold\n"
     ]
    }
   ],
   "source": [
    "# Use fewer repeats here for sake of brevity (these benchmarks take longer):\n",
    "num_repeats = 200\n",
    "multiple_outputs = True\n",
    "target_lags = range(-52, 0, 3)\n",
    "past_lags = range(-15, 0, 2)\n",
    "future_lags = range(-20, 0, 1)\n",
    "horizon = 10\n",
    "max_samples = None\n",
    "old_time, new_time = benchmark_training_data_generation(\n",
    "    num_repeats,\n",
    "    target_lags,\n",
    "    past_lags,\n",
    "    future_lags,\n",
    "    horizon,\n",
    "    max_samples,\n",
    "    multiple_outputs,\n",
    ")\n",
    "print(f\"Current implementation: {old_time} secs\")\n",
    "print(f\"New implementation: {new_time} secs\")\n",
    "print(f\"Speed up = {old_time/new_time} fold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b122b-24fa-4086-aea2-08e35f2e0595",
   "metadata": {},
   "source": [
    "## TODO: Prediction Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e81563-8f42-4a71-9300-f684d41fa769",
   "metadata": {},
   "source": [
    "### TODO: Test Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f84176ec-3f88-4fc6-bf67-cc933233fa57",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# def test_predicting_correctness():\n",
    "#     num_timesteps = 90\n",
    "#     target_series = create_index_series(num_timesteps, num_components=1, offset=10, start='5/1/1900',  freq='d')\n",
    "#     past_series = create_index_series(num_timesteps - 13, num_components=1, offset=30, freq='2d')\n",
    "#     future_series = create_index_series(num_timesteps + 5, num_components=1, offset=60, freq='3d')\n",
    "#     target_lag_combos = ([-1], [-2, -1], [-4, -3, -2, -1], [-6, -4, -2]) # ( [-1], [-2, -1], [-3, -2, -1], [-3, -1], [-5, -3, -1]) # [-1], [-1, -2, -3, -4], [-2, -4, -6]\n",
    "#     past_lag_combos = ([-1], [-2, -1], [-4, -3, -2, -1], [-6, -4, -2]) # ( [-1], [-2, -1], [-3, -2, -1], [-3, -1], [-5, -3, -1] )\n",
    "#     future_lag_combos = ([-1], [-2, -1], [-4, -3, -2, -1], [-6, -4, -2]) # ( [-1], [-2, -1], [-3, -2, -1], [-3, -1], [-5, -3, -1])\n",
    "#     max_samp_combos = [1000] # [1, 2, 3, 1000]\n",
    "#     param_combos = product(\n",
    "#         target_lag_combos, past_lag_combos, future_lag_combos, max_samp_combos\n",
    "#     )\n",
    "#     len_combos = (\n",
    "#         len(target_lag_combos)\n",
    "#         * len(past_lag_combos)\n",
    "#         * len(future_lag_combos)\n",
    "#         * len(max_samp_combos)\n",
    "#     )\n",
    "#     for i, (tl, pl, fl, max_samp) in enumerate(param_combos):\n",
    "#         (X, y, Ts) = _create_lagged_data(\n",
    "#             target_series,\n",
    "#             lags=tl,\n",
    "#             past_covariates=past_series,\n",
    "#             future_covariates=future_series,\n",
    "#             lags_past_covariates=pl,\n",
    "#             lags_future_covariates=fl,\n",
    "#             output_chunk_length=1,\n",
    "#             is_training=False,\n",
    "#             max_samples_per_ts=max_samp,\n",
    "#             multi_models=True\n",
    "#         )\n",
    "#         my_X, my_Ts = create_lagged_features(\n",
    "#             target_series=target_series,\n",
    "#             past_series=past_series,\n",
    "#             future_series=future_series,\n",
    "#             target_lags=tl,\n",
    "#             past_lags=pl,\n",
    "#             future_lags=fl,\n",
    "#             max_samples=max_samp,\n",
    "#         )\n",
    "#         print(tl, pl, fl, max_samp)\n",
    "#         # try:\n",
    "#         #     assert list(my_Ts)==list(Ts[0])\n",
    "#         # except:\n",
    "#         #     raise ValueError(\"Ts incorrect\")\n",
    "#         try:\n",
    "#             assert np.allclose(my_X.squeeze(), X.squeeze())\n",
    "#         except:\n",
    "#             print(Ts, my_Ts)\n",
    "#             print(X.shape, my_X.shape)\n",
    "#             print(X.squeeze())\n",
    "#             print(my_X.squeeze())\n",
    "#             raise ValueError(\"X incorrect\")\n",
    "\n",
    "#         if (i+1) % 1 == 0:\n",
    "#             print(f\"Passed {i+1}/{len_combos}\")\n",
    "\n",
    "\n",
    "# test_predicting_correctness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6257bd9f-e2a8-4e05-b7ee-0af4363ceeaf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "### Understanding Behaviour of `_create_lagged_data` when `is_training=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76500557-521a-4f14-a7e2-320fcd1673ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = 12\n",
    "target_series = create_index_series(num_timesteps, num_components=1, offset=10, freq=1)\n",
    "past_series = create_index_series(\n",
    "    num_timesteps - 1, num_components=1, offset=30, freq=2\n",
    ")\n",
    "future_series = create_index_series(\n",
    "    num_timesteps + 1, num_components=1, offset=60, freq=3\n",
    ")\n",
    "\n",
    "(X, y, Ts) = _create_lagged_data(\n",
    "    target_series,\n",
    "    lags=[-1],\n",
    "    past_covariates=past_series,\n",
    "    future_covariates=future_series,\n",
    "    lags_past_covariates=[-2],\n",
    "    lags_future_covariates=[-3],\n",
    "    output_chunk_length=10,\n",
    "    multi_models=False,\n",
    "    is_training=False,\n",
    "    max_samples_per_ts=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31ef948c-8675-4d27-8e4f-b2360b4bb8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21.]\n",
      " [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.stack([target_series.all_values().squeeze(), list(target_series.time_index)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8fe2cdd-dbe7-4f1e-879e-9d1e141b012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30. 31. 32. 33. 34. 35. 36. 37. 38. 39. 40.]\n",
      " [ 0.  2.  4.  6.  8. 10. 12. 14. 16. 18. 20.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.stack([past_series.all_values().squeeze(), list(past_series.time_index)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aba039cf-2137-418b-80ac-90da22beb11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60. 61. 62. 63. 64. 65. 66. 67. 68. 69. 70. 71. 72.]\n",
      " [ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27. 30. 33. 36.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.stack([future_series.all_values().squeeze(), list(future_series.time_index)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b9935fc-52fc-4d82-9779-14ce34718921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Int64Index([6], dtype='int64', name='time')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a058ed84-3d92-45dd-aa82-78500281de36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15., 32., 61.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41c55a30-7e4f-4ee2-ac40-519997c4f07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e956d509-9597-4441-a873-249e13a466e2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
